# Gesture Bot
A deep learning based project that can take gestures as input and actuate a bot through a microcontroller.

As a first step: 
The program can now recognise static ASL alphabet gestures in noiseless background with a test accuracy of 95%. Further improvements on introducing background independence in progress. 

1. Open CNN_ASL first if you want to make changest to the model architecture and retrain it. 
2. Or else open and run asl_predictor. It uses the pretrained saved model 'LeNet5_rmsprop.h5'. 

